{
  final HadoopProcess proc=runningProcsByJobId.get(job.id());
  if (proc != null) {
    if (log.isDebugEnabled())     log.debug("Updating job information for remote task process [proc=" + proc + ", meta="+ meta+ ']');
    if (meta.phase() == GridHadoopJobPhase.PHASE_COMPLETE) {
      if (log.isDebugEnabled())       log.debug("Completed job execution, will terminate child process [jobId=" + job.id() + ", proc="+ proc+ ']');
      runningProcsByJobId.remove(job.id());
      runningProcsByProcId.remove(proc.descriptor().processId());
      proc.terminate();
      return;
    }
    if (proc.initFut.isDone())     sendJobInfoUpdate(proc,meta);
 else {
      proc.initFut.listenAsync(new CI1<GridFuture<GridBiTuple<Process,GridHadoopProcessDescriptor>>>(){
        @Override public void apply(        GridFuture<GridBiTuple<Process,GridHadoopProcessDescriptor>> f){
          try {
            f.get();
            sendJobInfoUpdate(proc,meta);
          }
 catch (          GridException e) {
            if (log.isDebugEnabled())             log.debug("Failed to initialize child process (will skip job state notification) " + "[jobId=" + job.id() + ", meta="+ meta+ ", err="+ e+ ']');
          }
        }
      }
);
    }
  }
 else {
    GridHadoopMapReducePlan plan=meta.mapReducePlan();
    if (plan.mapperNodeIds().contains(ctx.localNodeId()) || plan.reducerNodeIds().contains(ctx.localNodeId()))     startProcess(job,meta.mapReducePlan());
  }
}
