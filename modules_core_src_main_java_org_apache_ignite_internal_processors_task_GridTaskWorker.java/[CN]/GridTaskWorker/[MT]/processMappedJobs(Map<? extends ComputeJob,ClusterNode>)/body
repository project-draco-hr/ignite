{
  if (F.isEmpty(jobs))   return;
  Collection<GridJobResultImpl> jobResList=new ArrayList<>(jobs.size());
  Collection<ComputeJobSibling> sibs=new ArrayList<>(jobs.size());
  for (  Map.Entry<? extends ComputeJob,ClusterNode> mappedJob : jobs.entrySet()) {
    ComputeJob job=mappedJob.getKey();
    ClusterNode node=mappedJob.getValue();
    if (job == null)     throw new IgniteCheckedException("Job can not be null [mappedJob=" + mappedJob + ", ses="+ ses+ ']');
    if (node == null)     throw new IgniteCheckedException("Node can not be null [mappedJob=" + mappedJob + ", ses="+ ses+ ']');
    IgniteUuid jobId=IgniteUuid.fromUuid(ctx.localNodeId());
    GridJobSiblingImpl sib=new GridJobSiblingImpl(ses.getId(),jobId,node.id(),ctx);
    jobResList.add(new GridJobResultImpl(job,jobId,node,sib));
    if (resCache)     sibs.add(sib);
    recordJobEvent(EVT_JOB_MAPPED,jobId,node,"Job got mapped.");
  }
synchronized (mux) {
    if (state != State.WAITING)     throw new IgniteCheckedException("Task is not in waiting state [state=" + state + ", ses="+ ses+ ']');
    if (resCache)     ses.addJobSiblings(sibs);
    if (jobRes == null)     jobRes=new HashMap<>();
    for (    GridJobResultImpl res : jobResList) {
      if (jobRes.put(res.getJobContext().getJobId(),res) != null)       throw new IgniteCheckedException("Duplicate job ID for remote job found: " + res.getJobContext().getJobId());
      res.setOccupied(true);
      if (resCache && jobRes.size() > ctx.discovery().size() && jobRes.size() % SPLIT_WARN_THRESHOLD == 0)       LT.warn(log,null,"Number of jobs in task is too large for task: " + ses.getTaskName() + ". Consider reducing number of jobs or disabling job result cache with "+ "@ComputeTaskNoResultCache annotation.");
    }
  }
  ses.onMapped();
  for (  GridJobResultImpl res : jobResList) {
    evtLsnr.onJobSend(this,res.getSibling());
    try {
      sendRequest(res);
    }
  finally {
synchronized (mux) {
        res.setOccupied(false);
      }
    }
  }
  processDelayedResponses();
}
