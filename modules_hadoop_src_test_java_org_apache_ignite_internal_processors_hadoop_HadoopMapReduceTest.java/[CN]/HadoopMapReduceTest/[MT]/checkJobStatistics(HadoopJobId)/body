{
  HadoopCounters cntrs=grid(0).hadoop().counters(jobId);
  HadoopPerformanceCounter perfCntr=HadoopPerformanceCounter.getCounter(cntrs,null);
  Map<String,SortedMap<Integer,Long>> tasks=new TreeMap<>();
  Map<String,Integer> phaseOrders=new HashMap<>();
  phaseOrders.put("submit",0);
  phaseOrders.put("prepare",1);
  phaseOrders.put("start",2);
  phaseOrders.put("Cstart",3);
  phaseOrders.put("finish",4);
  String prevTaskId=null;
  long apiEvtCnt=0;
  for (  T2<String,Long> evt : perfCntr.evts()) {
    String[] parsedEvt=evt.get1().split(" ");
    String taskId;
    String taskPhase;
    if ("JOB".equals(parsedEvt[0])) {
      taskId=parsedEvt[0];
      taskPhase=parsedEvt[1];
    }
 else {
      taskId=("COMBINE".equals(parsedEvt[0]) ? "MAP" : parsedEvt[0].substring(0,3)) + parsedEvt[1];
      taskPhase=("COMBINE".equals(parsedEvt[0]) ? "C" : "") + parsedEvt[2];
    }
    if (!taskId.equals(prevTaskId))     tasks.put(taskId,new TreeMap<Integer,Long>());
    Integer pos=phaseOrders.get(taskPhase);
    assertNotNull("Invalid phase " + taskPhase,pos);
    tasks.get(taskId).put(pos,evt.get2());
    prevTaskId=taskId;
    apiEvtCnt++;
  }
  for (  Map.Entry<String,SortedMap<Integer,Long>> task : tasks.entrySet()) {
    Map<Integer,Long> order=task.getValue();
    long prev=0;
    for (    Map.Entry<Integer,Long> phase : order.entrySet()) {
      assertTrue("Phase order of " + task.getKey() + " is invalid",phase.getValue() >= prev);
      prev=phase.getValue();
    }
  }
  final IgfsPath statPath=new IgfsPath("/xxx/yyy/zzz/" + jobId + "/performance");
  GridTestUtils.waitForCondition(new GridAbsPredicate(){
    @Override public boolean apply(){
      return igfs.exists(statPath);
    }
  }
,10000);
  BufferedReader reader=new BufferedReader(new InputStreamReader(igfs.open(statPath)));
  assertEquals(apiEvtCnt,HadoopTestUtils.simpleCheckJobStatFile(reader));
}
