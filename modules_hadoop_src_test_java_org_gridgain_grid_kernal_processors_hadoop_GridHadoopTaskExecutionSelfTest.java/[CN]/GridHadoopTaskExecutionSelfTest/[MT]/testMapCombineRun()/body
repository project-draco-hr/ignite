{
  int lineCnt=10001;
  String fileName="/testFile";
  prepareFile(fileName,lineCnt);
  totalLineCnt.set(0);
  Configuration cfg=new Configuration();
  cfg.setStrings("fs.ggfs.impl",GridGgfsHadoopFileSystem.class.getName());
  cfg.setBoolean(MAP_WRITE,true);
  Job job=Job.getInstance(cfg);
  job.setOutputKeyClass(Text.class);
  job.setOutputValueClass(IntWritable.class);
  job.setMapperClass(TestMapper.class);
  job.setCombinerClass(TestCombiner.class);
  job.setReducerClass(TestReducer.class);
  job.setNumReduceTasks(2);
  job.setInputFormatClass(TextInputFormat.class);
  FileInputFormat.setInputPaths(job,new Path("ggfs:///"));
  FileOutputFormat.setOutputPath(job,new Path("ggfs:///"));
  job.setJarByClass(getClass());
  GridHadoopProcessorAdapter hadoop=((GridKernal)grid(0)).context().hadoop();
  GridHadoopJobId jobId=new GridHadoopJobId(UUID.randomUUID(),2);
  GridFuture<?> fut=hadoop.submit(jobId,new GridHadoopDefaultJobInfo(job.getConfiguration()));
  fut.get();
  assertEquals(lineCnt,totalLineCnt.get());
  for (int g=0; g < gridCount(); g++)   ((GridKernal)grid(g)).context().hadoop().finishFuture(jobId).get();
}
