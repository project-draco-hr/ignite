{
  final HadoopJobId jobId=taskInfo.jobId();
  boolean lastMapperFinished=completedMappersCnt.incrementAndGet() == currMappers.size();
  if (status.state() == FAILED || status.state() == CRASHED) {
    transform(jobId,new RemoveMappersProcessor(prev,taskInfo.inputSplit(),status.failCause()));
    return;
  }
  IgniteInClosure<IgniteInternalFuture<?>> cacheUpdater=new CIX1<IgniteInternalFuture<?>>(){
    @Override public void applyx(    IgniteInternalFuture<?> f){
      Throwable err=null;
      if (f != null) {
        try {
          f.get();
        }
 catch (        IgniteCheckedException e) {
          err=e;
        }
      }
      transform(jobId,new RemoveMappersProcessor(prev,taskInfo.inputSplit(),err));
    }
  }
;
  if (lastMapperFinished)   ctx.shuffle().flush(jobId).listen(cacheUpdater);
 else   cacheUpdater.apply(null);
}
