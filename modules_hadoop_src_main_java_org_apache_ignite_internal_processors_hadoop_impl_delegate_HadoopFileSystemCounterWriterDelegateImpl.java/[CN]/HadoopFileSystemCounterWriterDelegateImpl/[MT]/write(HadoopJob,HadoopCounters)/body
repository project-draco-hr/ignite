{
  Configuration hadoopCfg=HadoopUtils.safeCreateConfiguration();
  final HadoopJobInfo jobInfo=job.info();
  final HadoopJobId jobId=job.id();
  for (  Map.Entry<String,String> e : ((HadoopDefaultJobInfo)jobInfo).properties().entrySet())   hadoopCfg.set(e.getKey(),e.getValue());
  String user=jobInfo.user();
  user=IgfsUtils.fixUserName(user);
  String dir=jobInfo.property(IgniteHadoopFileSystemCounterWriter.COUNTER_WRITER_DIR_PROPERTY);
  if (dir == null)   dir=DEFAULT_COUNTER_WRITER_DIR;
  Path jobStatPath=new Path(new Path(dir.replace(USER_MACRO,user)),jobId.toString());
  HadoopPerformanceCounter perfCntr=HadoopPerformanceCounter.getCounter(cntrs,null);
  try {
    hadoopCfg.set(MRJobConfig.USER_NAME,user);
    FileSystem fs=((HadoopV2Job)job).fileSystem(jobStatPath.toUri(),hadoopCfg);
    fs.mkdirs(jobStatPath);
    try (PrintStream out=new PrintStream(fs.create(new Path(jobStatPath,IgniteHadoopFileSystemCounterWriter.PERFORMANCE_COUNTER_FILE_NAME)))){
      for (      T2<String,Long> evt : perfCntr.evts()) {
        out.print(evt.get1());
        out.print(':');
        out.println(evt.get2().toString());
      }
      out.flush();
    }
   }
 catch (  IOException e) {
    throw new IgniteCheckedException(e);
  }
}
