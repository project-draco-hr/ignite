{
  Path outputDir=Files.createTempDirectory(GridGainWordCount2.class.getSimpleName() + "-output");
  try {
    URI testOutputDirURI=URI.create(outputDir.toString());
    File testInputFile=File.createTempFile(GridGainWordCount2.class.getSimpleName(),"-input");
    testInputFile.deleteOnExit();
    URI testInputFileURI=URI.create(testInputFile.getAbsolutePath());
    generateTestFile(testInputFile,"red",100,"blue",200,"green",150,"yellow",70);
    Long l=testInputFile.length() / 2;
    GridHadoopFileBlock fileBlock1=new GridHadoopFileBlock(null,testInputFileURI,0,l);
    GridHadoopFileBlock fileBlock2=new GridHadoopFileBlock(null,testInputFileURI,l,testInputFile.length() - l);
    Job hadoopJob=GridGainWordCount2.getJob(testInputFileURI.toString(),testOutputDirURI.toString());
    hadoopJob.setJobID(new JobID());
    GridHadoopJobId jobId=new GridHadoopJobId(new UUID(0,0),0);
    GridHadoopDefaultJobInfo jobInfo=new GridHadoopDefaultJobInfo(hadoopJob.getConfiguration());
    GridHadoopV2JobImpl gridJob=new GridHadoopV2JobImpl(jobId,jobInfo);
    GridHadoopTestTaskContext combine1Ctx=runMapCombineTask(fileBlock1,jobId,gridJob);
    GridHadoopTestTaskContext combine2Ctx=runMapCombineTask(fileBlock2,jobId,gridJob);
    GridHadoopTestTaskContext reduceCtx=new GridHadoopTestTaskContext(gridJob);
    reduceCtx.makeTreeOfWritables(combine1Ctx.mockOutput());
    reduceCtx.makeTreeOfWritables(combine2Ctx.mockOutput());
    GridHadoopTaskInfo taskInfo=new GridHadoopTaskInfo(null,GridHadoopTaskType.REDUCE,jobId,0,0,null);
    GridHadoopTask task=gridJob.createTask(taskInfo);
    task.run(reduceCtx);
    assertEquals("blue\t200\n" + "green\t150\n" + "red\t100\n"+ "yellow\t70\n",readFile(outputDir + "/part-r-00000"));
  }
  finally {
    FileUtils.deleteDirectory(outputDir.toFile());
  }
}
