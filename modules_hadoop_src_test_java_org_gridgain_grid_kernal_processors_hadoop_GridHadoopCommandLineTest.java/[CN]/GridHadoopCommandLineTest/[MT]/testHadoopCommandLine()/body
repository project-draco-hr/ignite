{
  assertEquals(0,executeHadoopCmd("fs","-ls","/"));
  assertEquals(0,executeHadoopCmd("fs","-mkdir","/input"));
  assertEquals(0,executeHadoopCmd("fs","-put",new File(testWorkDir,"test-data").getAbsolutePath(),"/input"));
  assertTrue(ggfs.exists(new GridGgfsPath("/input/test-data")));
  assertEquals(0,executeHadoopCmd("jar",examplesJar.getAbsolutePath(),"wordcount","/input","/output"));
  GridGgfsPath path=new GridGgfsPath("/users/" + System.getProperty("user.name") + "/");
  assertTrue(ggfs.exists(path));
  GridGgfsPath jobStatPath=null;
  for (  GridGgfsPath jobPath : ggfs.listPaths(path)) {
    assertNull(jobStatPath);
    jobStatPath=jobPath;
  }
  File locStatFile=new File(testWorkDir,"statistics");
  assertEquals(0,executeHadoopCmd("fs","-get",jobStatPath.toString() + "/statistics",locStatFile.toString()));
  long evtCnt=GridHadoopTestUtils.simpleCheckJobStatFile(new BufferedReader(new FileReader(locStatFile)));
  assertTrue(evtCnt >= 22);
  assertTrue(ggfs.exists(new GridGgfsPath("/output")));
  BufferedReader in=new BufferedReader(new InputStreamReader(ggfs.open(new GridGgfsPath("/output/part-r-00000"))));
  List<String> res=new ArrayList<>();
  String line;
  while ((line=in.readLine()) != null)   res.add(line);
  Collections.sort(res);
  assertEquals("[blue\t150, green\t200, red\t100, yellow\t50]",res.toString());
}
